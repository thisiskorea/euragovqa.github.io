@article{mmmu,
  title={{MMMU}: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert {AGI}},
  author={Yue, Xiang and Ni, Yuansheng and Zhang, Kai and Zheng, Tianyu and Liu, Ruoqi and Zhang, Ge and Stevens, Samuel and Jiang, Dongfu and Ren, Weiming and Sun, Yuxuan and others},
  journal={arXiv preprint arXiv:2311.16502},
  year={2023}
}

@article{mmlu,
  title={Measuring Massive Multitask Language Understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{mathvista,
  title={{MathVista}: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts},
  author={Lu, Pan and Bansal, Hritik and Xia, Tony and Liu, Jiacheng and Li, Chunyuan and Hajishirzi, Hannaneh and Cheng, Hao and Chang, Kai-Wei and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2310.02255},
  year={2023}
}

@article{examsv,
  title={{EXAMS-V}: A Multi-Discipline Multilingual Multimodal Exam Benchmark for Evaluating Vision Language Models},
  author={Das, Rocktim Jyoti and Camburu, Oana-Maria and Aralikatte, Rahul and Ivanova, Ekaterina and Kursun, Olga and Barrow, Joe and Vedantam, Ramakrishna and Lee, Kai-Wei and Lee, Nanyun},
  journal={arXiv preprint arXiv:2403.10378},
  year={2024}
}

@article{docvqa,
  title={{DocVQA}: A Dataset for {VQA} on Document Images},
  author={Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, CV},
  journal={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={2200--2209},
  year={2021}
}

@article{chartqa,
  title={{ChartQA}: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning},
  author={Masry, Ahmed and Long, Do Xuan and Tan, Jia Qing and Joty, Shafiq and Hoque, Enamul},
  journal={arXiv preprint arXiv:2203.10244},
  year={2022}
}

@article{textvqa,
  title={{TextVQA}: Towards Reading Text in Images to Answer Questions},
  author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8317--8326},
  year={2019}
}

@article{ocrbench,
  title={{OCRBench}: On the Hidden Mystery of {OCR} in Large Multimodal Models},
  author={Liu, Yuliang and Li, Zhang and Bai, Hongliang and Liu, Yang and Liu, Jingren and Zhang, Conghui and Zheng, Zhi and Lin, Bo},
  journal={arXiv preprint arXiv:2305.07895},
  year={2024}
}

@article{logicvqa,
  title={Can {VLMs} See Beyond Visual Perception? {A} Case Study on Complex Reasoning},
  author={Chen, Weifeng and Zhu, Xiaoyu and Shi, Minghang and Zhang, Yu and Chen, Wenbin and Ding, Zherong and Li, Yingnan and Wan, Xiaofei},
  journal={arXiv preprint arXiv:2402.12982},
  year={2024}
}

@article{multilingual_vlm,
  title={Multilingual Evaluation of Vision-Language Models},
  author={Liu, Yifan and Dou, Yaru and Wang, Yuxiang and Zhang, Kewei and Wang, Yuan and Fan, Wei},
  journal={arXiv preprint},
  year={2024}
}

@article{gpt4v,
  title={{GPT-4V}(ision) System Card},
  author={OpenAI},
  journal={OpenAI Technical Report},
  year={2023}
}

@article{gemini,
  title={Gemini: A Family of Highly Capable Multimodal Models},
  author={Google DeepMind},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{claude,
  title={The {Claude} Model Family},
  author={Anthropic},
  journal={Anthropic Technical Report},
  year={2024}
}

@article{qwen_vl,
  title={{Qwen-VL}: A Frontier Large Vision-Language Model with Versatile Abilities},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}

@article{internvl,
  title={{InternVL}: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
  journal={arXiv preprint arXiv:2312.14238},
  year={2023}
}

@article{llava,
  title={Visual Instruction Tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}
