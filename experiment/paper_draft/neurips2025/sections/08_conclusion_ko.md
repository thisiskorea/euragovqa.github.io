# Section 8: Conclusion (한국어 초안)

---

## 8.1 Summary of Findings

### 연구 배경 및 질문

Vision-Language Model(VLM)의 성능이 급격히 향상되면서, 각국 정부는 행정 문서 처리, 민원 자동화, 시험 채점 등에 AI 도입을 적극 검토하고 있다. 본 연구는 핵심적인 질문에 답하고자 했다:

> **"영어 벤치마크에서 우수한 VLM이 다른 나라의 공문서에서도 신뢰할 수 있는가?"**

### 핵심 발견

```
┌─────────────────────────────────────────────────────────────────┐
│                    CORE FINDINGS                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ❌ 신뢰할 수 없다.                                              │
│                                                                  │
│  1. 지역 효과가 과목 효과를 3.9배 압도                          │
│     • η²(Nation) = 0.126 vs η²(Task) = 0.043                    │
│     • Nation: p = 0.005** (significant)                         │
│     • Task: p = 0.40 (not significant)                          │
│                                                                  │
│  2. 23개 모델 중 82.6%에서 일관적 패턴                          │
│     • 19/23 모델이 Nation > Task 패턴                           │
│     • Binomial test: p = 0.0013                                 │
│                                                                  │
│  3. 극단적 성능 격차                                            │
│     • GPT-4o: EU 63.7% vs Japan 26.0% (37.7%p gap)             │
│     • 같은 모델, 다른 지역 → 랜덤 수준까지 추락                 │
│                                                                  │
│  4. 인식(Perception) 병목이 지배적                              │
│     • 실패의 72%가 OCR/문자 인식 관련                           │
│     • 추론 실패는 11%에 불과                                    │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 8.2 Contributions

본 연구의 기여는 다음과 같다:

### 1. 실증적 발견 (Empirical Finding)

**"VLM 성능은 과목 난이도보다 지역/언어에 의해 3.9배 더 크게 좌우된다."**

- 이는 "VLM은 범용 지능을 갖추었다"는 가정에 경종을 울린다
- 정부가 AI를 도입하기 전에 대상 지역에서 검증해야 하는 강력한 근거 제공

### 2. EuraGovExam 벤치마크

- 5개 지역 (한국, 일본, 대만, 인도, EU)
- 4개 문자체계 (Hangul, Japanese, Traditional Chinese, Latin/Devanagari)
- 8,000+ 실제 공무원 시험 문항
- 17개 과목 도메인
- **정부 AI 신뢰성 검증을 위한 최초의 체계적 벤치마크**

### 3. 진단 분석 방법론

- 176개 실패 사례의 수동 분류
- Perception vs Reasoning 병목 분해
- 지역별 병목 유형 식별
- 모델별 강약점 분석

### 4. 실용적 가이드라인

| 지역 | 주요 병목 | 권고 |
|------|-----------|------|
| Japan | OCR + Script | 일본어 특화 모델/전처리 필요 |
| Korea | OCR + Script | 한글 OCR 품질 검증 필수 |
| India | OCR + Script | Devanagari 인식 강화 필요 |
| EU | Reasoning | 현재 수준 OK, 추론 강화 시 개선 |
| Taiwan | Minimal | 현재 수준으로 도입 가능 |

---

## 8.3 Key Takeaway Message

```
┌─────────────────────────────────────────────────────────────────┐
│                     KEY TAKEAWAY                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  "정부가 AI를 믿고 쓰려 하지만,                                  │
│   지역/언어에 따라 성능이 3.9배 차이나므로                       │
│   대상 지역에서 반드시 검증해야 한다."                           │
│                                                                  │
│  ─────────────────────────────────────────────                   │
│                                                                  │
│  "Governments seek to deploy VLMs, but performance               │
│   varies by 3.9× across regions. Region-specific                 │
│   validation is REQUIRED before deployment."                     │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 8.4 Future Directions

### 단기 연구 과제

1. **추가 지역 확장**: 동남아, 중동, 아프리카, 중남미 지역 포함
2. **저자원 언어 평가**: 아랍어, 타밀어, 스와힐리어 등
3. **최신 모델 지속 평가**: GPT-5, Gemini 2.0 등 출시 시 업데이트

### 중기 연구 과제

1. **인과 관계 연구**: 왜 특정 문자체계에서 실패하는가?
2. **개선 방법 개발**: 지역별 fine-tuning, OCR 전처리 효과 검증
3. **실제 업무 평가**: 객관식을 넘어 실제 정부 업무 시뮬레이션

### 장기 연구 과제

1. **언어 불가지론적 VLM**: 문자체계에 강건한 새로운 아키텍처
2. **글로벌 정부 AI 표준**: 다국어 성능 기준 및 인증 체계
3. **AI 형평성 연구**: 기술 혜택의 균등한 분배를 위한 정책 연구

---

## 8.5 Final Remarks

VLM의 "범용 지능"에 대한 기대가 높아지는 가운데, 본 연구는 냉정한 현실을 보여준다. **MMMU에서 90%를 달성한 모델이 일본 공무원 시험에서는 26%로 추락할 수 있다.** 이는 단순한 학술적 발견이 아니라, 각국 정부가 AI 도입을 결정할 때 반드시 고려해야 할 실질적인 경고이다.

EuraGovExam이 정부 AI 신뢰성 검증의 표준 도구로 활용되기를 바라며, 이 연구가 더 공정하고 신뢰할 수 있는 다국어 AI 시스템 개발에 기여하기를 기대한다.

---

## Acknowledgments

[To be added: 데이터 제공, 연구비 지원 등]

---

## References

[논문 본문에서 인용된 참고문헌 - LaTeX 변환 시 추가]
