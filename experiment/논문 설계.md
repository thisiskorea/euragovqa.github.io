# EuraGov-Exam: Diagnosing Perception and Reasoning Bottlenecks in Image-Only Multimodal Evaluation

## Abstract
(최종 작성)
- 문제 제기: 기존 멀티모달 평가의 한계 (clean / text-first / instruction-heavy)
- 제안: 실제 공무원 시험 스캔 기반 image-only 벤치마크
- 핵심 결과 요약:
  - 국가/스크립트가 성능 분산의 주 요인
  - OCR 및 clean-text 개입을 통해 perception vs reasoning 병목 분리
  - 지역별 병목 전이(regional bottleneck shift) 관찰
- 시사점

---

## 1. Introduction
### 1.1 Background and Motivation
- 현실 시험 문서의 특성: 복잡한 레이아웃, 다언어, 스크립트, 저품질 스캔
- 기존 멀티모달 벤치마크의 한계

### 1.2 Gap in Existing Benchmarks
- OCR-first 또는 clean text 중심 평가
- perception과 reasoning 병목을 분리할 수 없음

### 1.3 EuraGov-Exam Overview
- 실제 공무원 시험 기반
- image-only 입력 (외부 텍스트 프롬프트 없음)
- 5개 지역, 다수 스크립트

### 1.4 Key Findings (Preview)
- 국가/스크립트가 성능 분산의 주요 요인
- perception bottleneck이 다수 지역에서 지배적
- OCR/clean-text 개입 시 지역별 회복률 차이

### 1.5 Contributions
- 고충실도 현실 시험 문서 벤치마크 제안
- leakage-aware, 재현 가능한 평가 프로토콜
- perception vs reasoning 병목의 개입 기반 진단
- 지역/스크립트별 병목 전이 분석

---

## 2. Related Work
### 2.1 Exam and Knowledge Benchmarks
- MMLU, AGIEval, EXAMS-V 등

### 2.2 Document Understanding Benchmarks
- DocVQA, ChartQA 등

### 2.3 Multimodal LLM Evaluation
- VLM reasoning 중심 평가의 한계

---

## 3. Dataset: EuraGov-Exam
### 3.1 Data Sources and Licensing
- 국가별 시험 출처
- 공개 경로 및 재배포 가능성
- 민감정보 제거 기준

### 3.2 Data Collection Pipeline
- 스캔 수집
- 페이지/문항 분리
- 전처리 여부 및 해상도 분포

### 3.3 Annotation and Verification
- 정답 출처 (공식 정답표)
- 라벨링 절차
- 검수 방식 및 샘플 검수율

### 3.4 Dataset Statistics
- 국가 / 언어 / 도메인 분포
- 레이아웃 유형 (표, 다단, 수식)
- 이미지 품질 분포

### 3.5 Leakage and Duplicate Audit
- perceptual hash 기반 near-duplicate 탐지
- 웹 유통 흔적 조사
- 연도별 hold-out 정책

---

## 4. Evaluation Protocol
### 4.1 Image-Only Setting Definition
- 외부 텍스트 입력 없음
- 지시문은 이미지 내부에만 존재
- OCR 및 tool 사용 금지

### 4.2 Models and Inference Details
- 모델 목록 및 버전
- 입력 해상도
- decoding 파라미터
- 샘플 수

### 4.3 Metrics
- Accuracy
- Confidence Interval (Wilson / bootstrap)
- Failure overlap

---

## 5. Benchmark Results
### 5.1 Overall Performance
- Closed-source vs Open-source
- Human baseline
- Random / heuristic baseline

### 5.2 Cross-Regional Performance Variance
- 국가별 성능 차이
- task variance 대비 nation variance 분석

### 5.3 Universal Failure Set
- 모든 모델이 실패한 문항
- 질적 사례 분석

---

## 6. Diagnosing Bottlenecks: Perception vs Reasoning
### 6.1 Failure Taxonomy
- Perception failure
- Reasoning failure
- Instruction misunderstanding
- Other
- 인간 검증 및 agreement 분석

### 6.2 OCR-Assisted Upper Bound
- Image → OCR → LLM 파이프라인
- 국가별 성능 회복률

### 6.3 Clean Text / Re-render Ablation
- 동일 문항의 텍스트 버전 평가
- reasoning-only 상한선 측정

### 6.4 Regional Bottleneck Shift
- 국가/스크립트별 병목 비중 변화
- 개입 실험 결과 종합

---

## 7. Robustness Analysis
- 해상도 저하
- 크롭
- 대비 변화에 따른 성능 민감도

---

## 8. Discussion
- reasoning SOTA와 document understanding의 괴리
- OCR + LLM 파이프라인의 시사점
- 공공/교육 평가에서의 의미

---

## 9. Limitations
- leakage 완전 차단의 어려움
- OCR 품질 편차
- 커버리지 한계

---

## 10. Conclusion
- 핵심 요약
- 향후 연구 방향

---

## Appendix / Data Card
- 데이터셋 카드 (수집, 정제, 품질, 라이선스)
- 추가 실험 결과
- 재현성 체크리스트
