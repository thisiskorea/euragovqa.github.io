import json
from pathlib import Path
from datasets import load_dataset

RESULTS_FILE = Path(__file__).parent / "results" / "vce_analysis.json"

with open(RESULTS_FILE, "r") as f:
    data = json.load(f)

noise_cases = data["noise_cases"]

print("=" * 70)
print(f"Visual Noise Cases Analysis ({len(noise_cases)} cases)")
print("=" * 70)

print("\n[1] ì§€ì—­ë³„ ë¶„í¬")
print("-" * 40)
by_nation = {}
for case in noise_cases:
    nation = case["nation"]
    by_nation[nation] = by_nation.get(nation, 0) + 1

for nation, count in sorted(by_nation.items(), key=lambda x: -x[1]):
    pct = count / len(noise_cases) * 100
    bar = "â–ˆ" * int(pct / 2)
    print(f"  {nation:<15} {count:>2}ê°œ ({pct:>5.1f}%) {bar}")

print("\n[2] ë„ë©”ì¸ë³„ ë¶„í¬")
print("-" * 40)
by_task = {}
for case in noise_cases:
    task = case["task"]
    by_task[task] = by_task.get(task, 0) + 1

for task, count in sorted(by_task.items(), key=lambda x: -x[1]):
    pct = count / len(noise_cases) * 100
    print(f"  {task:<20} {count:>2}ê°œ ({pct:>5.1f}%)")

print("\n[3] ì¼€ì´ìŠ¤ ìƒì„¸ ì •ë³´")
print("-" * 70)
print(f"{'#':<3} {'Index':<8} {'Nation':<12} {'Task':<15} {'Correct':<8} {'íŒ¨í„´'}")
print("-" * 70)

for i, case in enumerate(noise_cases):
    pattern = ""
    if case["track_a"] and case["track_b"] and not case["track_c"]:
        pattern = "Aâœ“ Bâœ“ Câœ— (ë‘˜ ë‹¤ ë§ëŠ”ë° í•©ì¹˜ë©´ í‹€ë¦¼)"
    elif not case["track_a"] and case["track_b"] and not case["track_c"]:
        pattern = "Aâœ— Bâœ“ Câœ— (í…ìŠ¤íŠ¸ë§Œ ë§ìŒ)"
    else:
        pattern = f"A{'âœ“' if case['track_a'] else 'âœ—'} B{'âœ“' if case['track_b'] else 'âœ—'} C{'âœ“' if case['track_c'] else 'âœ—'}"

    print(
        f"{i+1:<3} {case['index']:<8} {case['nation']:<12} {case['task']:<15} {case['correct_answer']:<8} {pattern}"
    )

print("\n[4] íŒ¨í„´ ë¶„ì„")
print("-" * 40)

pattern_both_correct = sum(1 for c in noise_cases if c["track_a"] and c["track_b"])
pattern_text_only = sum(1 for c in noise_cases if not c["track_a"] and c["track_b"])

print(
    f"  íŒ¨í„´ 1: ì´ë¯¸ì§€âœ“ + í…ìŠ¤íŠ¸âœ“ â†’ ë©€í‹°ëª¨ë‹¬âœ—  : {pattern_both_correct}ê°œ ({pattern_both_correct/len(noise_cases)*100:.1f}%)"
)
print(
    f"  íŒ¨í„´ 2: ì´ë¯¸ì§€âœ— + í…ìŠ¤íŠ¸âœ“ â†’ ë©€í‹°ëª¨ë‹¬âœ—  : {pattern_text_only}ê°œ ({pattern_text_only/len(noise_cases)*100:.1f}%)"
)
print()
print("  ğŸ’¡ íŒ¨í„´ 1 í•´ì„: ê°œë³„ì ìœ¼ë¡œëŠ” ë§ì¶”ëŠ”ë°, í•©ì¹˜ë©´ Fusion Interference ë°œìƒ")
print("  ğŸ’¡ íŒ¨í„´ 2 í•´ì„: ì´ë¯¸ì§€ê°€ ì›ë˜ ë„ì›€ ì•ˆ ë˜ëŠ”ë°, ë©€í‹°ëª¨ë‹¬ì—ì„œ ë°©í•´ê¹Œì§€ í•¨")

print("\n[5] ì´ë¯¸ì§€ ì €ì¥ (ì§ì ‘ í™•ì¸ìš©)")
print("-" * 40)

dataset = load_dataset("EuraGovExam/EuraGovExam", split="train")

output_dir = Path(__file__).parent / "visual_noise_images"
output_dir.mkdir(exist_ok=True)

for i, case in enumerate(noise_cases):
    idx = case["index"]
    item = dataset[idx]
    img = item["img"]

    filename = f"{i+1:02d}_{case['nation']}_{case['task']}_{idx}.png"
    filepath = output_dir / filename
    img.save(filepath)
    print(f"  ì €ì¥: {filename}")

print(f"\nì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {output_dir}")
print("\nì§ì ‘ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•˜ì—¬ ê³µí†µ íŠ¹ì„±ì„ ë¶„ì„í•˜ì„¸ìš”:")
print("  - ì„¸ë¡œì“°ê¸° ì—¬ë¶€")
print("  - í‘œ/ë‹¤ì´ì–´ê·¸ë¨ ì¡´ì¬")
print("  - ìˆ˜ì‹/ê¸°í˜¸ ë³µì¡ì„±")
print("  - ë ˆì´ì•„ì›ƒ ë³µì¡ì„±")
