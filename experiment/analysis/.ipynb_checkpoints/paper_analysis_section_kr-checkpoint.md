# 분석 (Analysis)

## 5. 실험 결과: 성능 격차는 균일하지 않다

### 5.1 국가별 성능 분포

23개 VLM 모델을 EuraGovExam 벤치마크에서 평가한 결과, 국가 간 성능 격차가 도메인 간 격차보다 체계적으로 크다는 것을 발견하였다. Table 1은 상위 5개 모델의 국가별 정확도를 Wilson 95% 신뢰구간과 함께 제시한다.

**Table 1.** 상위 모델의 국가별 정확도 (%, Wilson 95% CI)

| Model | Overall | Japan | India | S.Korea | EU | Taiwan |
|-------|---------|-------|-------|---------|-----|--------|
| Gemini-2.5-Pro | 86.99 | 87.59 ±1.28 | 69.23 ±2.20 | 91.12 ±1.28 | 88.08 ±1.77 | **95.51** ±1.74 |
| o3 | 84.26 | 82.37 ±1.48 | 68.64 ±2.21 | 90.06 ±1.35 | 84.49 ±1.98 | **93.72** ±2.03 |
| o4-mini | 79.40 | 82.52 ±1.47 | 63.38 ±2.29 | 82.49 ±1.71 | 76.95 ±2.30 | **92.29** ±2.23 |
| GPT-4o | 42.04 | **25.97** ±1.70 | 40.99 ±2.34 | 33.25 ±2.12 | 63.73 ±2.62 | 66.66 ±3.91 |
| Claude-Sonnet-4 | 63.29 | **45.85** ±1.93 | 62.51 ±2.30 | 62.41 ±2.18 | 76.43 ±2.32 | 87.28 ±2.77 |

모든 모델에서 **Taiwan이 가장 높은 정확도**를, **Japan 또는 India가 가장 낮은 정확도**를 보였다. 특히 GPT-4o의 경우 Taiwan(66.66%)과 Japan(25.97%) 간 **40.69%p**의 극단적인 성능 격차가 관찰되었으며, 이는 동일 모델 내에서 국가에 따라 성능이 2.5배 이상 차이날 수 있음을 시사한다.

### 5.2 분산 분해: 국가 vs 도메인

모델 성능의 변동 원인을 정량화하기 위해 국가별 분산과 도메인별 분산을 비교하였다. Figure 5에서 확인할 수 있듯이, **국가가 도메인보다 평균 2.52배 더 큰 분산**을 유발한다 (평균 국가 분산: 137.44, 평균 도메인 분산: 54.44).

이 결과는 VLM 성능이 "무엇을 묻는가" (도메인)보다 **"어디서 출제되었는가" (국가/언어/스크립트)**에 더 민감하게 반응한다는 것을 의미한다. 특히 저성능 모델에서 이 경향이 두드러진다: Gemini-2.5-flash-lite의 경우 국가 분산(702.09)이 도메인 분산(127.43)의 **5.5배**에 달했다.

### 5.3 통계적 유의성 검정

모델 간 성능 차이의 통계적 유의성을 검증하기 위해 Two-proportion z-test를 수행하고 Bonferroni 보정(α = 0.001)을 적용하였다. 상위 10개 모델의 45개 쌍 비교 중 **44개(97.8%)가 통계적으로 유의**하였으며, 유일하게 유의하지 않은 쌍은 o3(84.26%)와 Gemini-2.5-Pro(86.99%) 간 비교였다 (z = 2.47, p = 0.014 > 0.001).

---

## 6. 실패 분류 체계 (Failure Taxonomy)

### 6.1 분석 방법론

VLM 실패의 근본 원인을 파악하기 위해 **어려운 문제 177개**를 추출하여 체계적으로 분석하였다. 문제 선정은 Phase 1에서 확인된 난이도 패턴을 기반으로 층화 표집하였다: 어려운 국가(Japan, India) × 어려운 도메인(Earth Science, Geography, History, Economics, Engineering, Physics, Mathematics) 조합에서 60개, 둘 중 하나만 해당하는 경우 80개, 나머지 37개를 무작위 추출하였다.

각 문제 이미지에 대해 Gemini-2.0-Flash를 사용하여 **10개 실패 카테고리** 중 하나를 1차 원인으로, 최대 2개를 2차 원인으로 분류하였다: (1) 비라틴 스크립트, (2) OCR/텍스트 인식, (3) 수학/기호 해석, (4) 순수 추론/지식, (5) 다이어그램 이해, (6) 표/차트 구조, (7) 그림-텍스트 정렬, (8) 코드스위칭, (9) 다단 레이아웃, (10) 이미지 품질.

### 6.2 실패 원인 분포

176개 유효 분석 결과, **비라틴 스크립트 관련 실패가 전체의 40.3%**로 압도적인 1위를 차지하였다 (Table 2).

**Table 2.** 1차 실패 원인 분포

| Failure Category | Count | % |
|-----------------|-------|-----|
| **비라틴 스크립트** (세로쓰기, CJK, 힌디어) | 71 | 40.3% |
| OCR/텍스트 인식 | 31 | 17.6% |
| 수학/기호 해석 | 25 | 14.2% |
| 순수 추론/지식 부족 | 20 | 11.4% |
| 다이어그램 이해 | 12 | 6.8% |
| 표/차트 구조 | 11 | 6.3% |
| 그림-텍스트 정렬 | 4 | 2.3% |
| 기타 (코드스위칭, 다단 레이아웃) | 2 | 1.1% |

**시각적 인식 관련 실패(비라틴 스크립트 + OCR + 다이어그램 + 표)가 전체의 71.0%**를 차지하는 반면, **순수 추론/지식 부족은 11.4%**에 불과하였다. 이는 현재 VLM의 주요 병목이 "생각하는 능력"이 아닌 **"보는 능력"**에 있음을 시사한다.

### 6.3 국가별 실패 패턴: 병목 지점의 전이

가장 중요한 발견은 **실패 원인이 국가에 따라 체계적으로 다르다**는 점이다 (Table 3).

**Table 3.** 국가별 1차 실패 원인 분포 (%)

| Nation | Non-Latin Script | OCR | Math/Symbol | Pure Reasoning | Others |
|--------|-----------------|-----|-------------|----------------|--------|
| **Japan** (n=65) | 43.1% | 4.6% | 27.7% | 3.1% | 21.5% |
| **India** (n=32) | 56.3% | 40.6% | 3.1% | 0.0% | 0.0% |
| **S.Korea** (n=47) | 51.1% | 10.6% | 12.8% | 10.6% | 14.9% |
| **EU** (n=25) | 0.0% | 24.0% | 0.0% | **48.0%** | 28.0% |
| **Taiwan** (n=7) | 14.3% | 57.1% | 0.0% | 14.3% | 14.3% |

이 결과는 **"Regional Bottleneck Shift"** 현상을 명확히 보여준다:

- **CJK + India (비라틴 스크립트 국가)**: 실패의 50-56%가 스크립트/OCR 관련 → **Perception Bottleneck**
- **EU (라틴 스크립트 국가)**: 실패의 48%가 순수 추론/지식 부족 → **Reasoning Bottleneck**

즉, **동일한 VLM이라도 Japan 문제에서는 "글자를 읽지 못해서" 실패하고, EU 문제에서는 "읽었지만 답을 몰라서" 실패**한다.

### 6.4 도메인별 실패 패턴

도메인에 따른 실패 원인도 뚜렷한 패턴을 보인다 (Figure 10):

- **Physics, Mathematics**: 수학/기호 해석 실패가 34-41% (다이어그램 이해와 결합 시 50% 이상)
- **Biology, Engineering**: 비라틴 스크립트 실패가 54-61% (주로 일본어 문제)
- **Law, Administration**: 순수 추론/지식 실패가 36-42% (법률 조문 이해 필요)

### 6.5 시각적 요소 분석

분석 대상 문제의 시각적 특성을 정량화한 결과:

| Visual Element | Count | % of Questions |
|---------------|-------|----------------|
| 수학 수식/기호 포함 | 68 | **38.6%** |
| 표/테이블 포함 | 26 | 14.8% |
| 다이어그램 포함 | 24 | 13.6% |
| 손글씨 포함 | 0 | 0.0% |

**어려운 문제의 약 40%가 수학적 표기**를 포함하고 있으며, 이는 수식 렌더링과 기호 해석이 VLM 성능의 핵심 요인임을 시사한다.

---

## 7. 논의: Script Bias 가설

### 7.1 발견의 통합

위 분석 결과를 종합하면 다음과 같은 핵심 통찰을 도출할 수 있다:

**Finding 1.** 국가가 도메인보다 2.5배 더 큰 성능 분산을 유발한다.

**Finding 2.** 실패 원인의 71%가 시각적 인식 관련이며, 이 중 절반 이상이 비라틴 스크립트 문제이다.

**Finding 3.** 비라틴 스크립트 국가(CJK, India)에서는 Perception이 병목이지만, 라틴 스크립트 국가(EU)에서는 Reasoning이 병목이다.

이를 바탕으로 우리는 **Script Bias 가설**을 제안한다:

> 현재 VLM은 학습 데이터의 라틴 스크립트 편향으로 인해, 비라틴 문자(특히 세로쓰기 일본어, 복잡한 한자, 데바나가리)에서 체계적으로 낮은 시각적 인식 성능을 보인다. 이로 인해 동일한 난이도의 문제라도 스크립트에 따라 실패 모드가 근본적으로 달라진다.

### 7.2 함의

**벤치마킹 함의**: 다국어 VLM 평가 시 macro-average는 지역별 성능 격차를 은폐한다. 스크립트/국가별 층화 보고가 필수적이다.

**학습 데이터 함의**: 비라틴 스크립트 문서(특히 세로쓰기, 복잡한 레이아웃)의 학습 데이터 확충이 시급하다.

**모델 설계 함의**: OCR 전처리 파이프라인이나 스크립트별 특화 인코더 등, 인식 단계의 개선이 CJK/India 성능 향상에 효과적일 수 있다.

---

## 8. 제한점

본 분석에는 다음과 같은 제한점이 있다:

1. **Taxonomy 자동화**: 실패 원인 분류에 Gemini-2.0-Flash를 사용하였으며, 인간 검증은 수행하지 않았다. 향후 연구에서 소규모 인간 검증(n=50)을 통한 분류 신뢰도 검증이 필요하다.

2. **인과 추론의 한계**: 스크립트와 언어 난이도, 문화적 특성이 혼재되어 있어, 스크립트만의 순수 효과를 분리하기 어렵다.

3. **개입 실험 부재**: Clean-Text 상한선이나 OCR-assisted 파이프라인 등의 개입 실험을 통해 "Perception Gap"을 정량화하는 후속 연구가 필요하다.
